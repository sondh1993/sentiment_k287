from underthesea import word_tokenize, pos_tag, sent_tokenize
import re
from underthesea import word_tokenize, pos_tag, sent_tokenize
import numpy as np
# Count emojis positive and negative
negative_emojis = [
    "ğŸ˜", "ğŸ˜”", "ğŸ™", "â˜¹ï¸", "ğŸ˜•",
    "ğŸ˜¢", "ğŸ˜­", "ğŸ˜–", "ğŸ˜£", "ğŸ˜©",
    "ğŸ˜ ", "ğŸ˜¡", "ğŸ¤¬", "ğŸ˜¤", "ğŸ˜°",
    "ğŸ˜¨", "ğŸ˜±", "ğŸ˜ª", "ğŸ˜“", "ğŸ¥º",
    "ğŸ˜’", "ğŸ™„", "ğŸ˜‘", "ğŸ˜¬", "ğŸ˜¶",
    "ğŸ¤¯", "ğŸ˜³", "ğŸ¤¢", "ğŸ¤®", "ğŸ¤•",
    "ğŸ¥´", "ğŸ¤”", "ğŸ˜·", "ğŸ™…â€â™‚ï¸", "ğŸ™…â€â™€ï¸",
    "ğŸ™†â€â™‚ï¸", "ğŸ™†â€â™€ï¸", "ğŸ™‡â€â™‚ï¸", "ğŸ™‡â€â™€ï¸", "ğŸ¤¦â€â™‚ï¸",
    "ğŸ¤¦â€â™€ï¸", "ğŸ¤·â€â™‚ï¸", "ğŸ¤·â€â™€ï¸", "ğŸ¤¢", "ğŸ¤§",
    "ğŸ¤¨", "ğŸ¤«", "ğŸ‘", "ğŸ‘Š", "âœŠ", "ğŸ¤›", "ğŸ¤œ",
    "ğŸ¤š", "ğŸ–•"
]

positive_emojis = [
    "ğŸ˜„", "ğŸ˜ƒ", "ğŸ˜€", "ğŸ˜", "ğŸ˜†",
    "ğŸ˜…", "ğŸ¤£", "ğŸ˜‚", "ğŸ™‚", "ğŸ™ƒ",
    "ğŸ˜‰", "ğŸ˜Š", "ğŸ˜‡", "ğŸ¥°", "ğŸ˜",
    "ğŸ¤©", "ğŸ˜˜", "ğŸ˜—", "ğŸ˜š", "ğŸ˜™",
    "ğŸ˜‹", "ğŸ˜›", "ğŸ˜œ", "ğŸ¤ª", "ğŸ˜",
    "ğŸ¤—", "ğŸ¤­", "ğŸ¥³", "ğŸ˜Œ", "ğŸ˜",
    "ğŸ¤“", "ğŸ§", "ğŸ‘", "ğŸ¤", "ğŸ™Œ", "ğŸ‘", "ğŸ‘‹",
    "ğŸ¤™", "âœ‹", "ğŸ–ï¸", "ğŸ‘Œ", "ğŸ¤",
    "âœŒï¸", "ğŸ¤Ÿ", "ğŸ‘ˆ", "ğŸ‘‰", "ğŸ‘†",
    "ğŸ‘‡", "â˜ï¸"
]

positive_words = [
    "thÃ­ch", "tá»‘t", "xuáº¥t sáº¯c", "tuyá»‡t vá»i", "tuyá»‡t háº£o", "Ä‘áº¹p", "á»•n"
    "hÃ i lÃ²ng", "Æ°ng Ã½", "hoÃ n háº£o", "cháº¥t lÆ°á»£ng", "thÃº vá»‹", "nhanh"
    "tiá»‡n lá»£i", "dá»… sá»­ dá»¥ng", "hiá»‡u quáº£", "áº¥n tÆ°á»£ng",
    "ná»•i báº­t", "táº­n hÆ°á»Ÿng", "tá»‘n Ã­t thá»i gian", "thÃ¢n thiá»‡n", "háº¥p dáº«n",
    "gá»£i cáº£m", "tÆ°Æ¡i má»›i", "láº¡ máº¯t", "cao cáº¥p", "Ä‘á»™c Ä‘Ã¡o",
    "há»£p kháº©u vá»‹", "ráº¥t tá»‘t", "ráº¥t thÃ­ch", "táº­n tÃ¢m", "Ä‘Ã¡ng tin cáº­y", "Ä‘áº³ng cáº¥p",
    "háº¥p dáº«n", "an tÃ¢m", "khÃ´ng thá»ƒ cÆ°á»¡ng láº¡i", "thá»a mÃ£n", "thÃºc Ä‘áº©y",
    "cáº£m Ä‘á»™ng", "phá»¥c vá»¥ tá»‘t", "lÃ m hÃ i lÃ²ng", "gÃ¢y áº¥n tÆ°á»£ng", "ná»•i trá»™i",
    "sÃ¡ng táº¡o", "quÃ½ bÃ¡u", "phÃ¹ há»£p", "táº­n tÃ¢m",
    "hiáº¿m cÃ³", "cáº£i thiá»‡n", "hoÃ  nhÃ£", "chÄƒm chá»‰", "cáº©n tháº­n",
    "vui váº»", "sÃ¡ng sá»§a", "hÃ o há»©ng", "Ä‘am mÃª", "vá»«a váº·n", "Ä‘Ã¡ng tiá»n"
]
negative_words = [
    "kÃ©m", "tá»‡", "Ä‘au", "xáº¥u",
    "buá»“n", "rá»‘i", "thÃ´", "lÃ¢u"
    "tá»‘i", "chÃ¡n", "Ã­t", "má»", "má»ng",
    "lá»ng láº»o", "khÃ³", "cÃ¹i", "yáº¿u",
    "kÃ©m cháº¥t lÆ°á»£ng", "khÃ´ng thÃ­ch", "khÃ´ng thÃº vá»‹", "khÃ´ng á»•n"
    "khÃ´ng há»£p", "khÃ´ng Ä‘Ã¡ng", "khÃ´ng chuyÃªn nghiá»‡p",
    "khÃ´ng pháº£n há»“i", "khÃ´ng an toÃ n", "khÃ´ng phÃ¹ há»£p", "khÃ´ng thÃ¢n thiá»‡n", "khÃ´ng linh hoáº¡t", "khÃ´ng Ä‘Ã¡ng",
    "khÃ´ng áº¥n tÆ°á»£ng", "khÃ´ng tá»‘t", "cháº­m", "khÃ³ khÄƒn", "phá»©c táº¡p",
    "khÃ³ hiá»ƒu", "khÃ³ chá»‹u", "gÃ¢y khÃ³ dá»…", "rÆ°á»m rÃ ", "khÃ³ truy cáº­p",
    "tháº¥t báº¡i", "tá»“i tá»‡", "khÃ³ xá»­", "khÃ´ng thá»ƒ cháº¥p nháº­n", "tá»“i tá»‡","khÃ´ng rÃµ rÃ ng",
    "khÃ´ng cháº¯c cháº¯n", "rá»‘i ráº¯m", "khÃ´ng tiá»‡n lá»£i", "khÃ´ng Ä‘Ã¡ng", "chÆ°a Ä‘áº¹p", "khÃ´ng Ä‘áº¹p"
]
def save_emojis_to_file(emojis, file_name):
    with open(file_name, 'w', encoding='utf-8') as file:
        for emoji in emojis:
            file.write(emoji + '\n')

def save_text_to_file(texts, file_name):
    with open(file_name, 'w', encoding='utf-8') as file:
        for text in texts:
            file.write(text + '\n')

            
save_emojis_to_file(negative_emojis, 'negative_emojis_list.txt')
save_emojis_to_file(positive_emojis, 'positive_emojis_list.txt')
save_text_to_file(negative_words, 'negative_words_list.txt')
save_text_to_file(positive_words, 'positive_words_list.txt')

def file_to_dict(path):
    file = open(path, 'r', encoding = 'utf-8')
    lst = file.read().split('\n')
    dict = {}
    for line in lst:
        key, value = line.split('\t')
        dict[key] = str(value)
    file.close()
    return dict
def file_to_list(path):
    file = open(path, 'r', encoding = 'utf-8')
    lst = file.read().split('\n')
    file.close
    return lst

emoji_dict = file_to_dict(r'emojicon.txt')
teen_dict = file_to_dict(r'teencode.txt')
envi_dict = file_to_dict(r'english-vnmese.txt')
wrong_lst = file_to_list(r'wrong-word.txt')
stop_lst = file_to_list(r'vietnamese-stopwords.txt')
positive_emoji_dict = file_to_list(r'positive_emojis_list.txt')
negative_emoji_dict = file_to_list(r'negative_emojis_list.txt')

positive_words_dict = file_to_list(r'positive_words_list.txt')
negative_words_dict = file_to_list(r'negative_words_list.txt')

# file cÃ³ sáºµn clean text
emoji_dict = file_to_dict(r'emojicon.txt')
teen_dict = file_to_dict(r'teencode.txt')
envi_dict = file_to_dict(r'english-vnmese.txt')
wrong_lst = file_to_list(r'wrong-word.txt')
stop_lst = file_to_list(r'vietnamese-stopwords.txt')
######

def pre_text(text, emoji_dict, teen_dict, wrong_lst):
    doc = text.lower()
    doc = doc.replace("'",'')
    doc = re.sub(r'\.+', ".",doc)
    new_sentiment = ''
    for sentence in sent_tokenize(doc):
        # Cover emojicon
        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))
        # conver teencode
        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())
        # dell 
        pattern = r'(?i)\b[b-zÃ¡Ã¢Ã Äƒáº¯áº±áºµáº·áº¥áº§áº«áº©áº­bcdÄ‘eÃ©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡fghÃ­Ã¬á»‰Ä©á»‹jklmnoÃ³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£pqrstuÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±vwxyÃ½á»³á»·á»¹á»µz]+\b'
        sentence = ' '.join(re.findall(pattern, sentence))
        # del wrong words
        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())
        new_sentiment = new_sentiment+ sentence + '. '
    doc = new_sentiment
    doc = re.sub(r'\s+', ' ', doc).strip()
    return doc
################################
# Chuáº©n hÃ³a unicode tiáº¿ng viá»‡t
def loaddicchar(txt):
    uniChars = "Ã Ã¡áº£Ã£áº¡Ã¢áº§áº¥áº©áº«áº­Äƒáº±áº¯áº³áºµáº·Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ä‘Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÃ€Ãáº¢Ãƒáº Ã‚áº¦áº¤áº¨áºªáº¬Ä‚áº°áº®áº²áº´áº¶ÃˆÃ‰áººáº¼áº¸ÃŠá»€áº¾á»‚á»„á»†ÄÃŒÃá»ˆÄ¨á»ŠÃ’Ã“á»Ã•á»ŒÃ”á»’á»á»”á»–á»˜Æ á»œá»šá»á» á»¢Ã™Ãšá»¦Å¨á»¤Æ¯á»ªá»¨á»¬á»®á»°á»²Ãá»¶á»¸á»´Ã‚Ä‚ÄÃ”Æ Æ¯"
    unsignChars = "aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU"

    dic = {}
    char1252 = 'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£'.split(
        '|')
    charutf8 = "Ã |Ã¡|áº£|Ã£|áº¡|áº§|áº¥|áº©|áº«|áº­|áº±|áº¯|áº³|áºµ|áº·|Ã¨|Ã©|áº»|áº½|áº¹|á»|áº¿|á»ƒ|á»…|á»‡|Ã¬|Ã­|á»‰|Ä©|á»‹|Ã²|Ã³|á»|Ãµ|á»|á»“|á»‘|á»•|á»—|á»™|á»|á»›|á»Ÿ|á»¡|á»£|Ã¹|Ãº|á»§|Å©|á»¥|á»«|á»©|á»­|á»¯|á»±|á»³|Ã½|á»·|á»¹|á»µ|Ã€|Ã|áº¢|Ãƒ|áº |áº¦|áº¤|áº¨|áºª|áº¬|áº°|áº®|áº²|áº´|áº¶|Ãˆ|Ã‰|áºº|áº¼|áº¸|á»€|áº¾|á»‚|á»„|á»†|ÃŒ|Ã|á»ˆ|Ä¨|á»Š|Ã’|Ã“|á»|Ã•|á»Œ|á»’|á»|á»”|á»–|á»˜|á»œ|á»š|á»|á» |á»¢|Ã™|Ãš|á»¦|Å¨|á»¤|á»ª|á»¨|á»¬|á»®|á»°|á»²|Ã|á»¶|á»¸|á»´".split(
        '|')
    for i in range(len(char1252)):
        dic[char1252[i]] = charutf8[i]
    return re.sub(
        r'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£',
        lambda x: dicchar[x.group()], txt)

################################
def process_special_word(text):
    # cÃ³ thá»ƒ cÃ³ nhiá»u tá»« Ä‘áº·c biá»‡t cáº§n rÃ¡p láº¡i vá»›i nhau
    new_text = ''
    text_lst = text.split()
    i= 0
    # khÃ´ng, cháº³ng, cháº£...
    if 'khÃ´ng' in text_lst:
        while i <= len(text_lst) - 1:
            word = text_lst[i]
            if  word == 'khÃ´ng':
                next_idx = i+1
                if next_idx <= len(text_lst) -1:
                    word = word +'_'+ text_lst[next_idx]
                i= next_idx + 1
            else:
                i = i+1
            new_text = new_text + word + ' '
    else:
        new_text = text
    return new_text.strip()
################################
def translate_text(text):
    words = text.split()
    translated_words = [envi_dict.get(word.lower(), word) for word in words]
    return ' '.join(translated_words)
################################
def process_postag_thesea(text):
    new_document = ''
    for sentence in sent_tokenize(text):
        sentence = sentence.replace('.','')
        ###### POS tag
        lst_word_type = ['N','Np','A','AB','V','VB','VY','R']
        # lst_word_type = ['A','AB','V','VB','VY','R']
        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format="text"))))
        new_document = new_document + sentence + ' '
    ###### DEL excess blank space
    new_document = re.sub(r'\s+', ' ', new_document).strip()
    return new_document
################################
def remove_stop(text, stopwords):
    doc = ' '.join('' if word in stopwords else word for word in text.split())
    doc = re.sub(r'\s+', ' ', doc).strip()
    return doc
################################
def find_words(document, list_of_words):
    document_lower = document.lower()
    word_count = 0
    word_list = []

    for word in list_of_words:
        if word in document_lower:
            print(word)
            word_count += document_lower.count(word)
            word_list.append(word)

    return word_count, word_list
###############################################################
def count_value_text(row, find_text):
    row = row.lower()
    count = sum(1 for text in find_text if text in row)
    return count

def step_clean(df_sub):
    df_sub['words'] = df_sub['content'].apply(lambda x: pre_text(str(x), emoji_dict, teen_dict, wrong_lst))
    df_sub['words'] = df_sub['words'].apply(lambda x: loaddicchar(str(x)))
    df_sub['words'] = df_sub['words'].apply(lambda x: translate_text(x))
    # TÃ­nh toÃ¡n sá»‘ lÆ°á»£ng tá»« vÃ  emoji mang tÃ­nh cáº£m xÃºc
    df_sub['positive_words_count'] = df_sub['words'].apply(lambda x: count_value_text(str(x), positive_words_dict))
    df_sub['positive_emoji_count'] = df_sub['words'].apply(lambda x: count_value_text(str(x), positive_emoji_dict))
    df_sub['negative_words_count'] = df_sub['words'].apply(lambda x: count_value_text(str(x), negative_words_dict))
    df_sub['negative_emoji_count'] = df_sub['words'].apply(lambda x: count_value_text(str(x), negative_emoji_dict))
    
    df_sub['words'] = df_sub['words'].apply(lambda x: word_tokenize(x))
    df_sub['words'] = df_sub['words'].apply(lambda x: process_postag_thesea(str(x)))
    df_sub['words'] = df_sub['words'].apply(lambda x: remove_stop(str(x), stop_lst))
   
    df_sub['words_length'] = df_sub['words'].apply(lambda x: len(str(x).split()))
    # ThÃªm 2 cá»™t sentiment vÃ  Ä‘Ã¡nh giÃ¡ láº¡i rating
    df_sub['positive'] = df_sub['positive_emoji_count'] + df_sub['positive_words_count']
    df_sub['negative'] = df_sub['negative_emoji_count'] + df_sub['negative_words_count']
    # thÃªm cá»™t má»›i rating_new
    df_sub['rating_new'] = np.where(df_sub['positive'] > df_sub['negative'], df_sub['rating']+1, df_sub['rating'] -1 )
    # Táº¡o cá»™t má»›i sentiment káº¿t hÆ¡p tá»« rating 
    df_sub['sentiment'] = df_sub['rating_new'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutal')
    # XÃ³a dá»¯ liá»‡u thiáº¿u
    df_sub_new = df_sub.dropna()
    return df_sub_new

